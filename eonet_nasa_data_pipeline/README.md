Задача пайплайна — скачать сырые данные с сайта, трансформировать их в колоночный формат Parquet и загрузить в S3. 

В качестве хранилища буду использовать сервис Minio полностью совместимый с S3 файловый сервер, поэтому Apache Airflow будет работать с ним как с AWS S3 
(Это популярный сервис для хранения файлов от компании Amazon, также S3 можно рассматривать как распределенную файловую систему.).

Структура пайплайна

Пайплайн (DAG) будет состоять из следующих операторов:

`SimpleHttpOperator` - для проверки существования файла на сервере перед его загрузкой

`2 PythonOperator`:

`download_file` — загрузка файла с сайта и перекладывание на S3 в сжатом виде (gzip)

`to_parquet` — оператор скачивает файл, загруженный предыдущим оператором, и трансформирует его в формат Parquet, сохраняя результат в S3.

Выполнение последующего шага зависит от успешности предыдущего. Если необходимого файла на сервере нет (check_file), то выполнение загрузки нецелесообразно (download_file), за этим строго следит Airflow.


