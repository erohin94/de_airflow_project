# Пример

Пример создадания DAG с одним оператором, далее добавится ещё один и будет видно как описывать зависимость. Таким образом получится первый небольшой пайплайн.

**Скелет DAG**

Планировщик Airflow ищет все возможные DAG по наличию инстанса(объект, который был создан на основе шаблона или класса) объекта DAG в модуле (по пути, указанному в конфигурационном файле).

![image](https://github.com/user-attachments/assets/46993d7f-ebdb-4699-9ef8-47d8971b2412)

DAG должен быть доступен при импорте модуля/пакета планировщиком, поэтому его необходимо определять в глобальном пространстве имён. 

Также у каждого DAG должен быть уникальный dag_id, именно его вы видно в списке всех DAG, когда заходим в панель управления Airflow.

[Ссылка на простой DAG](https://github.com/erohin94/Data-Engineer/blob/main/Airflow/airflow_project/dags/first_dag.py)

Класс DAG умеет работать с контекстным менеджером with. 

В коде создается инстанс класса DAG, передаем ему уникальный dag_id, расписание запусков и параметры по умолчанию через default_args. 

Параметры по умолчанию удобны, когда хотим одни и те же настройки передать всем операторам, входящим в DAG. Также можно задавать индивидуальные настройки для каждого оператора. Например, количество перезапусков в случае ошибок, retries, или таймаут перед повторным запуском, retry_delay. Параметр start_date также может быть у каждого оператора свой.

У нас с вами получился простой DAG с одним лишь оператором — PythonOperator. Этот оператор принимает на вход callable (функцию, исполняемый класс или lambda выражение). Каждый оператор должен иметь уникальный task_id и dag к которому он относится.

Функция random_dice случайным образом генерирует число от 1 до 6, и в случае если выпало нечетное число возбуждает исключение ValueError. Обратите внимание, что в default_args мы задали настройки для перезапуска операторов в случае ошибок — retries=2, также таймаут между повторами равен 10 секундам, retry_delay. Это как раз поможет вам понять как Airflow ведёт себя в случае появления ошибок при выполнении кода.

Написанный DAG следует разместить в папке dags или той папке которая указана в конфигурационном пути.

Так же необходимо убедиться, что запущен планировщик и веб-сервер. Именно планировщик отвечает за обнаружение новых DAG.

Первый способ — это просто проверить, запущен ли контейнер с планировщиком через Docker.

Открыть терминал и выполнить команду: ```docker ps```. Это выведет список всех запущенных контейнеров. Среди них можно увидеть контейнер с именем, содержащим scheduler, если контейнер с планировщиком запущен.

![image](https://github.com/user-attachments/assets/cbfae9e5-1e38-46d5-a04a-2a2e61366d8a)

Так же можно проверить через: Логи контейнера, Веб-интерфейс Airflow и тд.

Если всё прошло без ошибок, то в панели управления должны увидеть свой первый DAG:

![image](https://github.com/user-attachments/assets/23cb4e40-9cae-4494-90ea-cc68da4f8aa1)

**Запуск DAG**

Мы указали:

```schedule_interval = daily```

```start_date = 2024-12-25```

Что означает, что наш DAG будет запускаться ежедневно, начиная с 25 декабря 2024 года.

Внимание, как только активируете DAG, планировщик автоматически запустит выполнение за все прошедшие дни, начиная с даты, указанной в start_date.

Когда я пишу эти строки на календаре 11 января 2025 года. Это значит, что активировав DAG, планировщик запустит выполнение с 25 декабря до 10 января включительно. Запуск за 11 января будет запланирован в полночь 12-го января, т.е. после 11 января 2024 года и 23:59:59 часов. Совокупно будет 18 запусков:

14 удачных запусков

![image](https://github.com/user-attachments/assets/0d8d1ad0-d490-428b-b944-a0af8e39bf9a)

4 неудачных запуска. На скриншоте видно, что запуск за 30 декабря, 1,3,9 января был неудачным даже с учётом дополнительных двух попыток. Получается, что во всех 3 запусках (1 запуск стандартный + 2 попытки) выпало нечетное число.

![image](https://github.com/user-attachments/assets/3b0f4d19-404b-48ef-a91d-29f2da7d239c)

![image](https://github.com/user-attachments/assets/d906ae43-109f-4eca-9701-d2ea495a8984)
