**Пример создадания DAG с одним оператором**

![image](https://github.com/user-attachments/assets/e724fdbe-4236-4f0d-b341-f4aeb1afc248)

------------------------------------

Планировщик Airflow ищет все возможные DAG по наличию инстанса(объект, который был создан на основе шаблона или класса) объекта DAG в модуле (по пути, указанному в конфигурационном файле).

![image](https://github.com/user-attachments/assets/51cf3f1d-2c91-45f8-bc12-8392171005ae)

DAG должен быть доступен при импорте модуля/пакета планировщиком, поэтому его необходимо определять в глобальном пространстве имён. 

Также у каждого DAG должен быть уникальный `dag_id`, именно его видно в списке всех DAG, когда заходим в панель управления Airflow.

Класс DAG умеет работать с контекстным менеджером `with`. 

В коде создается инстанс класса DAG, передаем ему уникальный `dag_id`, расписание запусков и параметры по умолчанию через `default_args`. 

Параметры по умолчанию удобны, когда хотим одни и те же настройки передать всем операторам, входящим в DAG. Также можно задавать индивидуальные настройки для каждого оператора. Например, количество перезапусков в случае ошибок, `retries`, или таймаут перед повторным запуском, `retry_delay`. Параметр `start_date` также может быть у каждого оператора свой.

Получился простой DAG с одним лишь оператором — `PythonOperator`. Этот оператор принимает на вход `callable` (функцию, исполняемый класс или `lambda` выражение). Каждый оператор должен иметь уникальный `task_id` и dag к которому он относится.

Функция `random_dice` случайным образом генерирует число от 1 до 6, и в случае если выпало нечетное число возбуждает исключение `ValueError`. В `default_args` мы задали настройки для перезапуска операторов в случае ошибок — `retries=2`, также таймаут между повторами равен 10 секундам, `retry_delay`. Это как раз поможет понять как Airflow ведёт себя в случае появления ошибок при выполнении кода.

Написанный DAG следует разместить в папке `dags` или той папке которая указана в конфигурационном пути.

Так же необходимо убедиться, что запущен планировщик и веб-сервер. Именно планировщик отвечает за обнаружение новых DAG.

Первый способ — это просто проверить, запущен ли контейнер с планировщиком через Docker.

Открыть терминал и выполнить команду: `docker ps`. Это выведет список всех запущенных контейнеров. Среди них можно увидеть контейнер с именем, содержащим `scheduler`, если контейнер с планировщиком запущен.

![image](https://github.com/user-attachments/assets/090477db-f2ec-4898-92f8-41fb38acdacc)

Так же можно проверить через: Логи контейнера, Веб-интерфейс Airflow и тд.

Если всё прошло без ошибок, то в панели управления должны увидеть свой первый DAG:

![image](https://github.com/user-attachments/assets/0569a37e-7c24-432d-b2a9-55b227c38de8)

------------------------------------------------

**Запуск DAG**

Мы указали:

```schedule_interval = daily```

```start_date = 2025-5-20```

Что означает, что наш DAG будет запускаться ежедневно, начиная с 20 мая 2025 года.

Внимание, как только активируете DAG, планировщик автоматически запустит выполнение за все прошедшие дни, начиная с даты, указанной в 'start_date'.

Когда я пишу эти строки на календаре 14 июня 2025 года. Это значит, что активировав DAG, планировщик запустит выполнение с 20 мая до 14 июня включительно. Запуск за 15 июня будет запланирован в полночь 15-го июня, т.е. после 14 июня 2025 года и 23:59:59 часов. Совокупно будет 26 запусков:

23 удачных запусков

![image](https://github.com/user-attachments/assets/19f42ee6-b70e-42c9-a067-bb1c28694328)

3 неудачных запуска. На скриншоте видно, что запуск за 23 мая, 2,7 июня был неудачным даже с учётом дополнительных двух попыток. Получается, что во всех 3 запусках (1 запуск стандартный + 2 попытки) выпало нечетное число.

![image](https://github.com/user-attachments/assets/f40f7280-cb76-4d77-9813-13f0b8e83d06)

![image](https://github.com/user-attachments/assets/e26e3f5a-2478-4da1-920b-571e48abbcca)

